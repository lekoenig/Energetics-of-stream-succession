---
title: ""
author: ""
date: ""
output: html_document
---
  
### Attempt to fit Ricker model to river GPP data

*File generated by LE Koenig on `r Sys.Date()`*  
*Full Rmarkdown document with code can be viewed [here](https://github.com/lekoenig/Energetics-of-stream-succession/blob/master/Ricker_Identifiability.Rmd).*  

<br>

```{r,echo=FALSE,warning=FALSE,message=FALSE}

# Load packages:
library(dplyr)         # general data cleaning and manipulation
library(ggplot2)       # create plots
library(cowplot)       # plot formatting
library(patchwork)     # plot formatting
library(grid)          # plot formatting
library(lubridate)     # format timestamps
library(dataRetrieval) # interface with NWIS 
library(tidybayes)     # easily extract draws from Bayesian models 
library(sbtools)       # interface with ScienceBase

source("./R/Analysis_Functions.R")

```

#### Problem  
I am attempting to fit a Ricker (modified logistic) model to time series of river gross primary production (GPP) following storm disturbances. In this model, the growth dynamics of photosynthetically-active algal biomass, combined with daily light, determine daily rates of GPP:  

$$P_t = L_t \times B_t$$  
where $L_t$ is relativized light (i.e., daily light normalized by maximum daily light; unitless) and $B_t$ is the photosynthetically-active biomass present on a given day (g C m$^{-2}$). The temporal dynamics of algal biomass following scouring stormflows approximate density-dependent logistic growth, which I have thus far represented using a Ricker model:  
  
$$B_{t+1} = B_{t} + e^{r(1-{B_t/K)}}$$ 

where $B$ represents the photosynthetically-active biomass at days t and t+1, respectively, $r$ is the maximum specific growth rate (day$^{-1}$), and $K$ is the biomass carrying capacity (g C m$^{-2}$). To implement the process model and account for model process error ($\sigma_{proc}$), biomass was log-transformed and eqn. 3 rearranged as follows:

$$logB_{t+1} = logB_{t} + r - b\times B_t + \epsilon_t, \;\;\;\;\;\;\epsilon_t \sim N(0,\sigma_{proc})$$  

Note that $-r$/$K$ has been replaced with a new parameter, $b$ in the process model. I implemented the observation and process models within a Bayesian framework using STAN and the rstan package (Stan Development Team 2020) in R (R Core Team 2020), such that model parameters $r$, $b$, $B_t$, $\sigma_{obs}$, and $\sigma_{proc}$ are estimated based on model likelihood and stated priors. **The problem that I'm having is that parameters r and b are inherently correlated, which I think is leading to issues with sampling and model identifiability.** Below I outline my attempts to fit this model on *simulated* GPP data:  

```{r,echo=FALSE,warning=FALSE,fig.height=3,fig.width=3}

# Simulate the data:

# use fake data where GPP saturates:
storm <- read.csv("./data/fakedata/GPP_sat_testing_fakedata.csv",header=TRUE) %>% mutate(date = as.Date(as.POSIXct(as.character(date), format="%m/%d/%y")))
storm %>% ggplot() + geom_point(aes(x=date,y=GPP_daily_mean),color="darkgreen") + theme_classic()

##===================================================================##
##             Generate *simulated* GPP time series                  ##
##===================================================================##


set.seed(1011)
# Simulate data according to Ricker model to see if we can retrieve parameters:

# Simulate data across how many storms?
no_storms <- 10

# Define parameter values:
r <- 0.53                                    # specific growth rate
r.true.err <- (r + rnorm(10,0,0.05))
K <- 15                                      # biomass carrying capacity (g C m-2)
K.true.err <- K + rnorm(10,0,1)
b <- -r.true.err/K.true.err                  # substitute for r/K ("b")
#sigma_proc <- 0.1                            # process error (based on log biomass data so this is really a scale parameter)
#sigma_obs <- rnorm(1,mean(obs_err$GPP_daily_sd,na.rm = TRUE),sd(obs_err$GPP_daily_sd,na.rm=TRUE))  # observation/measurement error
sigma_obs <- 0.1                             # effectively "turn off" observation error
sigma_proc <- 0.01                          # effectively "turn off" process error

# initialize time series:
dT <- 1                                             # time step
t <- seq(from=1,to=length(storm$date),by=dT)        # for now, all simulated storms are the same length
L <- storm$light_rel_smooth                         # relativized light - 3 day moving average (unitless)
GPP.pred <- rep(NA,length(t))
GPP.pred[1] <- 0.45                                 # Starting GPP; g O2 m^-2 d^-1
B <- rep(NA,length(t))
B[1] <- log(GPP.pred[1]/L[1])                               

# Create data frame to hold simulated data across j number of storms (defined by no_storms above):
sim_dat <- data.frame(storm_id = numeric(),time = integer(),light=numeric(),B = numeric(),GPP.pred = numeric())

# Simulate GPP given above parameters:
for(j in 1:no_storms){
  
  for(i in 1:length(t)){
    B[i+1] <- B[i] + r.true.err[j] + b[j]*exp(B[i]) + rnorm(1,mean=0,sd = sigma_proc)
    GPP.pred[i] <- L[i] * (exp(B[i])) + rnorm(1,mean=0,sd=sigma_obs)
  }
  
  df <- data.frame(storm_id = rep(j,length(t)), time = t,light=L,B = B[c(1:length(t))], GPPsim = GPP.pred)
  df2 <- cbind(df,storm$GPP_daily_sd) %>% rename("GPP_sd" = "storm$GPP_daily_sd")
  sim_dat <- rbind(sim_dat,df2)  
  
}

# For now, isolate one storm to test non-hierarchical version of Ricker model:
storm1 <- sim_dat[which(sim_dat$storm_id==1),]
ypred <- storm1$GPPsim

# Does simulated GPP *look like* the data?
storm$GPP_sim <- ypred
#storm %>% ggplot() + geom_point(aes(x=date,y=GPP_daily_mean),color="darkgreen") + geom_line(aes(x=date,y=GPP_daily_mean),alpha=.5,color="darkgreen") + theme_classic() #+ geom_point(aes(x=date,y=GPP_sim),color="darkblue")

# Create a list housing the simulated data:
fake_data <- list(N=length(storm1$time),GPP=storm1$GPPsim,light=storm1$light,GPP_sd = storm1$GPP_sd)

```

<br>  

#### Model iterations  

**1. First try fitting model with essentially no observation or process error**  
  
The data were simulated with process error = 0.01 and observation error = 0.1. The priors were both set to $$sigma \sim N(0,0.1)$$  
  
The traceplots show some difficulty with sampling and convergence issues:  

```{r,echo=FALSE,warning=FALSE,cache=TRUE,message=FALSE,results="hide"}

fit_noerr <- rstan::stan("./stan/Ricker_mod.stan",data=fake_data,iter=4000,chains=4,
                   control = list(stepsize = 0.5,adapt_delta=0.99,max_treedepth=10))

```

```{r,echo=FALSE,warning=FALSE,cache=TRUE,message=FALSE,results="hide",fig.width=6,fig.height=3.8}

rstan::traceplot(fit_noerr, pars= c("r", "b", "sigma_proc","sigma_obs"))

```

```{r,echo=FALSE,warning=FALSE,cache=TRUE,message=FALSE,results="hide",fig.width=12,fig.height=3.8}

## Extract posterior probability distributions for parameters:
fit_extract<-rstan::extract(fit_noerr) # pulls out our mcmc chains

## Plot parameters:
rplot <- post.plot(fit_extract$r) + geom_vline(xintercept=r.true.err[1],color="black",lty=2) + labs(x="r") + ggtitle(label ="Param: r")
bplot <- post.plot(fit_extract$b) + geom_vline(xintercept=(b[1]),color="black",lty=2) + labs(x="b") + ggtitle(label ="Param: b")
sigmaplot <- post.plot(fit_extract$sigma_proc) + geom_vline(xintercept=sigma_proc,color="black",lty=2) + labs(x="sigma_proc") + ggtitle(label ="Process error")
obsplot <- post.plot(fit_extract$sigma_obs) + geom_vline(xintercept=sigma_obs,color="black",lty=2) + labs(x="sigma_obs") + ggtitle(label ="Obs error")

sim_plot <- rplot + bplot + sigmaplot + obsplot + plot_layout(ncol=2)

## Plot joint distribution r + b:
bayesplot::color_scheme_set("blue")
joint_param_plot <- bayesplot::mcmc_scatter(as.array(fit_noerr),pars=c("r","b"),size=1.5,alpha=0.5) + theme_classic()
joint_param_plot_dens <- ggExtra::ggMarginal(joint_param_plot, type = "density",fill="darkblue",alpha=.25)

joint_error_plot <- bayesplot::mcmc_scatter(as.array(fit_noerr),pars=c("sigma_obs","sigma_proc"),size=1.5,alpha=0.5) + theme_classic()
joint_error_plot_dens <- ggExtra::ggMarginal(joint_error_plot, type = "density",fill="darkblue",alpha=.25)

joint_plot <- plot_grid(joint_param_plot_dens,joint_error_plot_dens,ncol=2)

plots <- plot_grid(sim_plot,joint_plot,ncol=2)
print(plots)

```

```{r,echo=FALSE,warning=FALSE,fig.width=9,fig.height=3.2}

# Plot actual fit of the model to the data:
post_GPP2 <- data.frame(GPPmod = fit_extract$GPPmod)  %>%
            tidyr::pivot_longer(data = .,cols=starts_with("GPP"),names_to = "day", values_to = "value") %>%
            mutate(timestep = as.integer(substr(day,8,11))) %>% arrange(.,timestep) %>% 
            left_join(.,storm1[,c("time","GPPsim")],by=c("timestep"="time"))

storm1$GPPtilde <- apply(fit_extract$GPP_tilde,2,median)
r2.print <- round(summary(lm(storm1$GPPtilde~storm1$GPPsim))$r.squared,3)
grob.r2 <- grobTree(textGrob(paste("r2 = ",r2.print,sep=""), x=0.08,  y=0.9, hjust=0,
           gp=gpar(col="black", fontsize=11)))

plot_grid(
storm1 %>% ggplot() + geom_abline(slope=1,intercept=0,lty=2) +
           geom_point(aes(x=GPPsim,y=GPPtilde),color="black",size=2) + 
           labs(x=expression(Simulated~GPP),y=expression(GPP[posterior~predictive]))+
           annotation_custom(grob.r2)+ theme_classic() ,
post_GPP2 %>% ggplot() + geom_point(aes(x=timestep,y=value,color="yrep"),alpha=0.5) + 
             geom_point(aes(x=timestep,y=GPPsim,color="y")) +
             scale_color_manual(values=c("blue","gray75"),name="",labels=c(expression(y),expression(y[rep]))) + 
             theme_classic() + labs(x="Day",y="GPP")+ theme(legend.text.align = 0),
ncol=2,rel_widths = c(0.5,1))

```

<br>  

**2a. Fitting model with observation and process error**   
  
In this model, the data were simulated with observation error = 0.2 and process error = 0.1 (10% of log-biomass). The priors were both set to standard normal:  
$$sigma \sim N(0,1)$$  
  
The traceplots show some difficulty with sampling and convergence issues (but perhaps improved over model 1 above):  


```{r,echo=FALSE,warning=FALSE}


##===================================================================##
##             Generate *simulated* GPP time series                  ##
##===================================================================##

set.seed(1011)
# Simulate data according to Ricker model to see if we can retrieve parameters:

# Simulate data across how many storms?
no_storms <- 10

# Define parameter values:
r <- 0.53                                    # specific growth rate
r.true.err <- (r + rnorm(10,0,0.05))
K <- 15                                      # biomass carrying capacity (g C m-2)
K.true.err <- K + rnorm(10,0,1)
b <- -r.true.err/K.true.err                  # substitute for r/K ("b")
sigma_proc <- 0.1                            # process error (based on log biomass data so this is really a scale parameter)
#sigma_obs <- rnorm(1,mean(obs_err$GPP_daily_sd,na.rm = TRUE),sd(obs_err$GPP_daily_sd,na.rm=TRUE))  # observation/measurement error
sigma_obs <- 0.2                             # effectively "turn off" observation error

# initialize time series:
dT <- 1                                             # time step
t <- seq(from=1,to=length(storm$date),by=dT)        # for now, all simulated storms are the same length
L <- storm$light_rel_smooth                         # relativized light - 3 day moving average (unitless)
GPP.pred <- rep(NA,length(t))
GPP.pred[1] <- 0.45                                 # Starting GPP; g O2 m^-2 d^-1
B <- rep(NA,length(t))
B[1] <- log(GPP.pred[1]/L[1])                               

# Create data frame to hold simulated data across j number of storms (defined by no_storms above):
sim_dat <- data.frame(storm_id = numeric(),time = integer(),light=numeric(),B = numeric(),GPP.pred = numeric())

# Simulate GPP given above parameters:
for(j in 1:no_storms){
  
  for(i in 1:length(t)){
    B[i+1] <- B[i] + r.true.err[j] + b[j]*exp(B[i]) + rnorm(1,mean=0,sd = sigma_proc)
    GPP.pred[i] <- L[i] * (exp(B[i])) + rnorm(1,mean=0,sd=sigma_obs)
  }
  
  df <- data.frame(storm_id = rep(j,length(t)), time = t,light=L,B = B[c(1:length(t))], GPPsim = GPP.pred)
  df2 <- cbind(df,storm$GPP_daily_sd) %>% rename("GPP_sd" = "storm$GPP_daily_sd")
  sim_dat <- rbind(sim_dat,df2)  
  
}

# For now, isolate one storm to test non-hierarchical version of Ricker model:
storm1 <- sim_dat[which(sim_dat$storm_id==1),]
ypred <- storm1$GPPsim

# Does simulated GPP *look like* the data?
storm$GPP_sim <- ypred
#storm %>% ggplot() + geom_point(aes(x=date,y=GPP_daily_mean),color="darkgreen") + geom_line(aes(x=date,y=GPP_daily_mean),alpha=.5,color="darkgreen") + theme_classic() #+ geom_point(aes(x=date,y=GPP_sim),color="darkblue")

# Create a list housing the simulated data:
fake_data <- list(N=length(storm1$time),GPP=storm1$GPPsim,light=storm1$light,GPP_sd = storm1$GPP_sd)

```

```{r,echo=FALSE,warning=FALSE,cache=TRUE,message=FALSE,results="hide",fig.width=6,fig.height=3.8}

fit_seterr <- rstan::stan("./stan/Ricker_mod_obserr.stan",data=fake_data,iter=4000,chains=4,
                   control = list(stepsize = 0.5,adapt_delta=0.99,max_treedepth=10))

rstan::traceplot(fit_seterr, pars= c("r", "b", "sigma_proc","sigma_obs"))

```

```{r,echo=FALSE,warning=FALSE,cache=TRUE,message=FALSE,results="hide",fig.width=12,fig.height=3.8}

## Extract posterior probability distributions for parameters:
fit_extract2<-rstan::extract(fit_seterr) # pulls out our mcmc chains

## Plot parameters:
rplot <- post.plot(fit_extract2$r) + geom_vline(xintercept=r.true.err[1],color="black",lty=2) + labs(x="r") + ggtitle(label ="Param: r")
bplot <- post.plot(fit_extract2$b) + geom_vline(xintercept=(b[1]),color="black",lty=2) + labs(x="b") + ggtitle(label ="Param: b")
sigmaplot <- post.plot(fit_extract2$sigma_proc) + geom_vline(xintercept=sigma_proc,color="black",lty=2) + labs(x="sigma_proc") + ggtitle(label ="Process error")
obsplot <- post.plot(fit_extract2$sigma_obs) + geom_vline(xintercept=sigma_obs,color="black",lty=2) + labs(x="sigma_obs") + ggtitle(label ="Obs error")

sim_plot <- rplot + bplot + sigmaplot + obsplot + plot_layout(ncol=2)

## Plot joint distribution r + b:
joint_param_plot <- bayesplot::mcmc_scatter(as.array(fit_seterr),pars=c("r","b"),size=1.5,alpha=0.5) + theme_classic()
joint_param_plot_dens <- ggExtra::ggMarginal(joint_param_plot, type = "density",fill="darkblue",alpha=.25)

joint_error_plot <- bayesplot::mcmc_scatter(as.array(fit_seterr),pars=c("sigma_obs","sigma_proc"),size=1.5,alpha=0.5) + theme_classic()
joint_error_plot_dens <- ggExtra::ggMarginal(joint_error_plot, type = "density",fill="darkblue",alpha=.25)

joint_plot <- plot_grid(joint_param_plot_dens,joint_error_plot_dens,ncol=2)

plots2 <- plot_grid(sim_plot,joint_plot,ncol=2)
print(plots2)


```

```{r,echo=FALSE,warning=FALSE,fig.width=9,fig.height=3.2}

# Plot actual fit of the model to the data:
post_GPP2 <- data.frame(GPPmod = fit_extract2$GPPmod)  %>%
            tidyr::pivot_longer(data = .,cols=starts_with("GPP"),names_to = "day", values_to = "value") %>%
            mutate(timestep = as.integer(substr(day,8,11))) %>% arrange(.,timestep) %>% 
            left_join(.,storm1[,c("time","GPPsim")],by=c("timestep"="time"))

storm1$GPPtilde <- apply(fit_extract2$GPP_tilde,2,median)
r2.print <- round(summary(lm(storm1$GPPtilde~storm1$GPPsim))$r.squared,3)
grob.r2 <- grobTree(textGrob(paste("r2 = ",r2.print,sep=""), x=0.08,  y=0.9, hjust=0,
           gp=gpar(col="black", fontsize=11)))

plot_grid(
storm1 %>% ggplot() + geom_abline(slope=1,intercept=0,lty=2) +
           geom_point(aes(x=GPPsim,y=GPPtilde),color="black",size=2) + 
           labs(x=expression(Simulated~GPP),y=expression(GPP[posterior~predictive]))+
           annotation_custom(grob.r2)+ theme_classic() ,
post_GPP2 %>% ggplot() + geom_point(aes(x=timestep,y=value,color="yrep"),alpha=0.5) + 
             geom_point(aes(x=timestep,y=GPPsim,color="y")) +
             scale_color_manual(values=c("blue","gray75"),name="",labels=c(expression(y),expression(y[rep]))) + 
             theme_classic() + labs(x="Day",y="GPP")+ theme(legend.text.align = 0),
ncol=2,rel_widths = c(0.5,1))

```
  
<br>  

**2b. Fitting model with observation and process error**   
  
In this model, the data were simulated with observation error equal to the mean of GPP_daily_sd (Appling et al. 2018) and process error = 0.1 (10% of log-biomass). The priors were set to:  
$$sigma_{proc} \sim N(0,1)$$  
  
$$sigma_{obs} \sim N(mean(GPP_{sd}),sd(GPP_{sd}))$$  

  

```{r,echo=FALSE,warning=FALSE}


##===================================================================##
##             Generate *simulated* GPP time series                  ##
##===================================================================##

# observation error:
obs_err <- readRDS("./data/out/model_fits_filtered.rds") %>% .[[which(names(.)=="nwis_01608500")]] %>%
           select(date,GPP_daily_mean,GPP_daily_sd)

set.seed(1011)
# Simulate data according to Ricker model to see if we can retrieve parameters:

# Simulate data across how many storms?
no_storms <- 10

# Define parameter values:
r <- 0.53                                    # specific growth rate
r.true.err <- (r + rnorm(10,0,0.05))
K <- 15                                      # biomass carrying capacity (g C m-2)
K.true.err <- K + rnorm(10,0,1)
b <- -r.true.err/K.true.err                  # substitute for r/K ("b")
sigma_proc <- 0.1                            # process error (based on log biomass data so this is really a scale parameter)
sigma_obs <- rnorm(1,mean(obs_err$GPP_daily_sd,na.rm = TRUE),sd(obs_err$GPP_daily_sd,na.rm=TRUE))  # observation/measurement error
#sigma_obs <- 0.2                             # effectively "turn off" observation error

# initialize time series:
dT <- 1                                             # time step
t <- seq(from=1,to=length(storm$date),by=dT)        # for now, all simulated storms are the same length
L <- storm$light_rel_smooth                         # relativized light - 3 day moving average (unitless)
GPP.pred <- rep(NA,length(t))
GPP.pred[1] <- 0.45                                 # Starting GPP; g O2 m^-2 d^-1
B <- rep(NA,length(t))
B[1] <- log(GPP.pred[1]/L[1])                               

# Create data frame to hold simulated data across j number of storms (defined by no_storms above):
sim_dat <- data.frame(storm_id = numeric(),time = integer(),light=numeric(),B = numeric(),GPP.pred = numeric())

# Simulate GPP given above parameters:
for(j in 1:no_storms){
  
  for(i in 1:length(t)){
    B[i+1] <- B[i] + r.true.err[j] + b[j]*exp(B[i]) + rnorm(1,mean=0,sd = sigma_proc)
    GPP.pred[i] <- L[i] * (exp(B[i])) + rnorm(1,mean=0,sd=sigma_obs)
  }
  
  df <- data.frame(storm_id = rep(j,length(t)), time = t,light=L,B = B[c(1:length(t))], GPPsim = GPP.pred)
  df2 <- cbind(df,storm$GPP_daily_sd) %>% rename("GPP_sd" = "storm$GPP_daily_sd")
  sim_dat <- rbind(sim_dat,df2)  
  
}

# For now, isolate one storm to test non-hierarchical version of Ricker model:
storm1 <- sim_dat[which(sim_dat$storm_id==1),]
ypred <- storm1$GPPsim

# Does simulated GPP *look like* the data?
storm$GPP_sim <- ypred
#storm %>% ggplot() + geom_point(aes(x=date,y=GPP_daily_mean),color="darkgreen") + geom_line(aes(x=date,y=GPP_daily_mean),alpha=.5,color="darkgreen") + theme_classic() #+ geom_point(aes(x=date,y=GPP_sim),color="darkblue")

# Create a list housing the simulated data:
fake_data <- list(N=length(storm1$time),GPP=storm1$GPPsim,light=storm1$light,GPP_sd = storm1$GPP_sd)



```

```{r,echo=FALSE,cache=TRUE,warning=FALSE,message=FALSE,results="hide",fig.width=6,fig.height=3.8}

fit_obserr <- rstan::stan("./stan/Ricker_mod_obserr_daily.stan",data=fake_data,iter=4000,chains=4,
                   control = list(stepsize = 0.5,adapt_delta=0.99,max_treedepth=10))

rstan::traceplot(fit_obserr, pars= c("r", "b", "sigma_proc","sigma_obs"))

```

```{r,echo=FALSE,warning=FALSE,cache=TRUE,message=FALSE,results="hide",fig.width=12,fig.height=3.8}

## Extract posterior probability distributions for parameters:
fit_extract3<-rstan::extract(fit_obserr) # pulls out our mcmc chains

## Plot parameters:
rplot <- post.plot(fit_extract3$r) + geom_vline(xintercept=r.true.err[1],color="black",lty=2) + labs(x="r") + ggtitle(label ="Param: r")
bplot <- post.plot(fit_extract3$b) + geom_vline(xintercept=(b[1]),color="black",lty=2) + labs(x="b") + ggtitle(label ="Param: b")
sigmaplot <- post.plot(fit_extract3$sigma_proc) + geom_vline(xintercept=sigma_proc,color="black",lty=2) + labs(x="sigma_proc") + ggtitle(label ="Process error")
obsplot <- post.plot(fit_extract3$sigma_obs) + geom_vline(xintercept=sigma_obs,color="black",lty=2) + labs(x="sigma_obs") + ggtitle(label ="Obs error")

sim_plot <- rplot + bplot + sigmaplot + obsplot + plot_layout(ncol=2)

## Plot joint distribution r + b:
joint_param_plot <- bayesplot::mcmc_scatter(as.array(fit_obserr),pars=c("r","b"),size=1.5,alpha=0.5) + theme_classic()
joint_param_plot_dens <- ggExtra::ggMarginal(joint_param_plot, type = "density",fill="darkblue",alpha=.25)

joint_error_plot <- bayesplot::mcmc_scatter(as.array(fit_obserr),pars=c("sigma_obs","sigma_proc"),size=1.5,alpha=0.5) + theme_classic()
joint_error_plot_dens <- ggExtra::ggMarginal(joint_error_plot, type = "density",fill="darkblue",alpha=.25)

joint_plot <- plot_grid(joint_param_plot_dens,joint_error_plot_dens,ncol=2)

plots3 <- plot_grid(sim_plot,joint_plot,ncol=2)
print(plots3)


```

```{r,echo=FALSE,warning=FALSE,fig.width=9,fig.height=3.2}

# Plot actual fit of the model to the data:
post_GPP2 <- data.frame(GPPmod = fit_extract3$GPPmod)  %>%
            tidyr::pivot_longer(data = .,cols=starts_with("GPP"),names_to = "day", values_to = "value") %>%
            mutate(timestep = as.integer(substr(day,8,11))) %>% arrange(.,timestep) %>% 
            left_join(.,storm1[,c("time","GPPsim")],by=c("timestep"="time"))

storm1$GPPtilde <- apply(fit_extract3$GPP_tilde,2,median)
r2.print <- round(summary(lm(storm1$GPPtilde~storm1$GPPsim))$r.squared,3)
grob.r2 <- grobTree(textGrob(paste("r2 = ",r2.print,sep=""), x=0.08,  y=0.9, hjust=0,
           gp=gpar(col="black", fontsize=11)))

plot_grid(
storm1 %>% ggplot() + geom_abline(slope=1,intercept=0,lty=2) +
           geom_point(aes(x=GPPsim,y=GPPtilde),color="black",size=2) + 
           labs(x=expression(Simulated~GPP),y=expression(GPP[posterior~predictive]))+
           annotation_custom(grob.r2)+ theme_classic() ,
post_GPP2 %>% ggplot() + geom_point(aes(x=timestep,y=value,color="yrep"),alpha=0.5) + 
             geom_point(aes(x=timestep,y=GPPsim,color="y")) +
             scale_color_manual(values=c("blue","gray75"),name="",labels=c(expression(y),expression(y[rep]))) + 
             theme_classic() + labs(x="Day",y="GPP")+ theme(legend.text.align = 0),
ncol=2,rel_widths = c(0.5,1))

```

<br>  

**3. Explicitly modeling the covariance between parameters r and b**   
  
In this model, the data were simulated with observation error equal to the mean of GPP_daily_sd (Appling et al. 2018) and process error = 0.1 (10% of log-biomass). The priors were set to:  
$$sigma_{proc} \sim N(0,1)$$  
  
$$sigma_{obs} \sim N(mean(GPP_{sd}),sd(GPP_{sd}))$$  

In the Ricker model formulated here, $b$ is equal to $r/K$ (see problem statement at top), so we *expect* that these parameters would be correlated. I have tried to explicitly model the correlation of $r$ and $b$ by putting a bivariate normal prior on the two parameters, and then re-parameterizing the prior to its non-centered form. The Cholesky decomposed correlation matrix ($L$) shows that the correlation between $r$ and $b$ is about -0.06. By reformulating the bivariate normal prior we can draw from two independent standard normal distributions.  

```{r,echo=FALSE,cache=TRUE,warning=FALSE,message=FALSE,results="hide",fig.width=6,fig.height=3.8}

fit_corrparams <- rstan::stan("./stan/Ricker_mod_corrparams.stan",data=fake_data,iter=6000,chains=4,
                   control = list(stepsize = 0.5,adapt_delta=0.99,max_treedepth=13))

rstan::traceplot(fit_corrparams, pars= c("beta[1]", "beta[2]", "sigma_proc","sigma_obs"))

```

```{r,echo=FALSE,warning=FALSE}

summary_corrparams <- rstan::summary(fit_corrparams, 
                      pars = c("beta[1]", "beta[2]","beta_tilde[1]","beta_tilde[2]","sigma_b[1]","sigma_b[2]",
                               "sigma_proc","sigma_obs","L"), 
                      probs = c(0.1, 0.9))$summary
print(summary_corrparams)

```

<br>  

The goal here is that the transformed parameters (beta) are highly correlated, but **sampled parameters** (beta_tilde) are not:


```{r,echo=FALSE,warning=FALSE,message=FALSE,results="hide",fig.width=7,fig.height=3.5}

draws_beta <- as.matrix(fit_corrparams, pars = "beta")
draws_betatilde <- as.matrix(fit_corrparams, pars = "beta_tilde")
plot_grid(
bayesplot::mcmc_scatter(draws_beta),
bayesplot::mcmc_scatter(draws_betatilde),
ncol=2)

```

However, it doesn't seem to me like explicitly accounting for the correlated nature of $r$ and $b$ has improved our ability to recover the set known parameter values (dashed lines in figure below) and therefore the model is still non-identifiable. I have tried to read up on methods for [reparameterization](https://mc-stan.org/docs/2_27/stan-users-guide/reparameterization-section.html) in stan, but I'm feeling out over my skis on this problem - it's possible I've coded up the covariance incorrectly, or have misinterpreted the output. The stan model is [here](https://github.com/lekoenig/Energetics-of-stream-succession/blob/master/stan/Ricker_mod_corrparams.stan) for reference, and I appreciate any feedback!


```{r,echo=FALSE,warning=FALSE,cache=TRUE,message=FALSE,results="hide",fig.width=6,fig.height=3.8}

# Extract posterior probability distributions for parameters:
fit_extract_corrparams <- rstan::extract(fit_corrparams) # pulls out our mcmc chains

# Plot parameters:
rplot <- post.plot(fit_extract_corrparams$beta[,1]) + geom_vline(xintercept=r.true.err[1],color="black",lty=2) + labs(x="r") + ggtitle(label ="Recovery rate")
bplot <- post.plot(fit_extract_corrparams$beta[,2]) + geom_vline(xintercept=(b[1]),color="black",lty=2) + labs(x="b") + ggtitle(label ="Parameter equal to r/K")
sigmaplot <- post.plot(fit_extract_corrparams$sigma_proc) + geom_vline(xintercept=sigma_proc,color="black",lty=2) + labs(x="sigma_proc") + ggtitle(label ="Process error")
obsplot <- post.plot(fit_extract_corrparams$sigma_obs) + geom_vline(xintercept=sigma_obs,color="black",lty=2) + labs(x="sigma_obs") + ggtitle(label ="Obs error")

sim_plot <- rplot + bplot + sigmaplot + obsplot + plot_layout(ncol=2)
print(sim_plot)


```


```{r,echo=FALSE,warning=FALSE,fig.width=9,fig.height=3.2}

storm1 <- sim_dat[which(sim_dat$storm_id==1),]


# Plot actual fit of the model to the data:
post_GPP2 <- data.frame(GPPmod = fit_extract_corrparams$GPPmod)  %>%
            tidyr::pivot_longer(data = .,cols=starts_with("GPP"),names_to = "day", values_to = "value") %>%
            mutate(timestep = as.integer(substr(day,8,11))) %>% arrange(.,timestep) %>% 
            left_join(.,storm1[,c("time","GPPsim")],by=c("timestep"="time"))

storm1$GPPtilde <- apply(fit_extract_corrparams$GPP_tilde,2,median)
r2.print <- round(summary(lm(storm1$GPPtilde~storm1$GPPsim))$r.squared,3)
grob.r2 <- grobTree(textGrob(paste("r2 = ",r2.print,sep=""), x=0.08,  y=0.9, hjust=0,
           gp=gpar(col="black", fontsize=11)))

plot_grid(
storm1 %>% ggplot() + geom_abline(slope=1,intercept=0,lty=2) +
           geom_point(aes(x=GPPsim,y=GPPtilde),color="black",size=2) + 
           labs(x=expression(Simulated~GPP),y=expression(GPP[posterior~predictive]))+
           annotation_custom(grob.r2)+ theme_classic() ,
post_GPP2 %>% ggplot() + geom_point(aes(x=timestep,y=value,color="yrep"),alpha=0.5) + 
             geom_point(aes(x=timestep,y=GPPsim,color="y")) +
             scale_color_manual(values=c("blue","gray75"),name="",labels=c(expression(y),expression(y[rep]))) + 
             theme_classic() + labs(x="Day",y="GPP")+ theme(legend.text.align = 0),
ncol=2,rel_widths = c(0.5,1))

```
